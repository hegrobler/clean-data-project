Coursera Cleaning Data Project
========================================================

This file documents the **run_analysis.R** script. It describes each of the steps completed in the **run_analysis.R** script in detail.

The following summarizes the environment that the tests were run in. If you run into any issues please ensure that all the packages listed below are loaded:
```{r}
sessionInfo()
Sys.time()
```

Step 1: Configure directory and file paths 
--------------------------------
The first line indicates the directory where **run_analysis.R** is located.

**Please adjust this value to suit the environment that it is run on**

```{r Step1}
path = getwd()
if (grep("clean-data-project", getwd()) == FALSE) {
  path <- paste(getwd(), "clean-data-project", sep="/")  
}

message(paste("Path:",path))

if (!file.exists(path)) {
  stop("Could not find the specified folder. Please upadte the path above")
}

#Master data
labelsFile <- paste(path,"/UCI HAR Dataset/activity_labels.txt", sep="")
featuresFile <- paste(path,"/UCI HAR Dataset/features.txt", sep="")

#Test / Training data
trainDataFile <- paste(path,"/UCI HAR Dataset/train/X_train.txt", sep="")
trainSubjectFile <- paste(path, "/UCI HAR Dataset/train/subject_train.txt", sep="")
trainLabelFile <- paste(path, "/UCI HAR Dataset/train/y_train.txt", sep="") 

testDataFile <- paste(path,"/UCI HAR Dataset/test/X_test.txt", sep="")
testSubjectFile <- paste(path, "/UCI HAR Dataset/test/subject_test.txt", sep="")
testLabelFile <- paste(path, "/UCI HAR Dataset/test/y_test.txt", sep="")
```

Step 2: Download the data into folder clean-data-project
--------------------------------
This step may take some time to complete. In order to run the script more than once you should:
* Manually download the (zip file)[https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip]
* Extract the contents to **UCI HAR Dataset** folder. 
  NOTE: This folder must be in the same location as the **run_analysis.R** file
* Comment out the following 4 lines by placing a # in front of each line. Note that this will not run in the Rmd file as its main purpose is to document **run_analysis.R**. Commenting out the lines should be done in **run_analysis.R** if the files are already present

```
temp <- tempfile()
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip", temp)
unzip(temp, exdir=path)
unlink(temp)
```

Step 3: Declare checkFileExists function
--------------------------------
This function is used to determine is a specific file exists. If it does not then it will print a message and stop the script execution

**Parameters:**
* **file**: Path to the file
* **file**: Description of the file. This is used to make the error message more helpful

```{r Step3}
checkFileExists <- function (file, description) {
    
  if (!file.exists(file)) {
    stop(paste(description, "file does not exist. Path: ", file))
  }
}

```

Step 4: Declare loadDataset function
--------------------------------
This function loads data from the different files and merges the data together into one dataset. It can be re-used to load the training set as well as the test set

**Parameters:**
* **subjectFile**: The subjects file eg. subject_test.txt
* **labelFile**: The activity labels file eg. y_test.txt
* **dataFile**: The main data file eg. X_test.txt

See **run_analysis.md** for more information on these files and the their contents

```{r Step4}
loadDataset <- function(subjectFile, labelFile, dataFile) {
  #Check that the files exist
  checkFileExists(subjectFile, "Subject")
  checkFileExists(labelFile, "Labels")
  checkFileExists(dataFile, "Dataset")
  
  #Load subject data
  subject <- read.csv(subjectFile, header=FALSE, sep=" ", col.names=c("subjectId"))
  
  #Load activityLables data
  activityLabels <- read.csv(labelFile, header=FALSE, sep=" ", col.names=c("activityLabelId"))
  
  #load data
  dataset <- read.csv(dataFile, header=FALSE, sep="", col.names=features$featureName)
  
  #Ensure that the lines from the three files correspond to ensure that there is no missing data
  if (nrow(activityLabels) != nrow(dataset) || nrow(dataset) != nrow(subject)) {
    print("The amount of rows in the dataset, subject and activity label files are not equal")
    print(paste("Dataset:", nrow(dataset),"Subject:",nrow(subject), "Activity Labels:", nrow(activityLabels)))
    stop()
  }
  
  #Add a subjectId column to the dataset based on the subject file
  dataset$subjectId <- subject$subjectId
  
  #Add a activityLabelId column to the dataset based on the activityLables file
  dataset$activityLabelId <- activityLabels$activityLabelId
  
  return(dataset)
}
```

Step 5: Declare getColumnsContaining function
--------------------------------
This function is used to extract specific columns from a data frame based on a naming pattern.

**Parameters:**
* **x**: Data frame to filter
* **patterns**: A character vector containing the naming patterns of columns to extract. Matching consist of a simple contains. Eg pattern "mean" will extract all columns that have mean anywhere in the column name. 

```{r step5}
getColumnsContaining <- function(x, patterns) {
  
  columnIndexes <- c();
  
  for(i in 1:length(patterns)){
    #Extract the column indexes of the columns that must be included
    indexes <- grep(patterns[i], names(x), fixed = TRUE)
    columnIndexes <- c(columnIndexes, indexes)
  }
  
  #Sort the columns by index so that they are in the same order as before
  columnIndexes <- sort(columnIndexes)
  
  x[columnIndexes]
}
```
Step 6: Load activity labels
--------------------------------
The activity labels are loaded from the specified file and appropriate column names assigned

```{r step6}
activities <- read.csv(labelsFile, header=FALSE, sep=" ")
names(activities) <- c("activityId", "activityName")

```
This is some sample content from the file
```{r echo=FALSE}
head(activities)
```

Step 7: Load features and remove all non-alphanumeric characters from the names
--------------------------------

As indicated in the CodeBook.md file, there are some characters that are not allowed in column names. These characters include (), and -. R normally replace these characters automatically with full stops. Eg tBodyAcc-mean()-X becomes tBodyAcc.mean...X. These characters were removed in order to ensure consistency and compatibility with other programming languages. For example tBodyAcc-mean()-X is changed to become tBodyAccmeanX. Keeping the name consistent with the original feature name ensures that studies are comparable irrespective of the original dataset being used or the output of this exercise.


```{r step7}
features <- read.csv(featuresFile, header=FALSE, sep=" ")
names(features) <- c("featureId", "featureName")
```

This is some sample content bedore the names are cleansed
```{r echo=FALSE}
head(features)
```

Remove all characters that are not numbers or letters
```{r step7b}
features$featureName <- gsub("[^[:alnum:] ]", "", features$featureName)
features$featureName <- make.names(features$featureName, unique=TRUE)
```
This is some sample content after the names have been cleansed
```{r echo=FALSE}
head(features)
```

Step 8: Load the training and test data set and validate that the columns correspond 
--------------------------------
```{r step8}
train <- loadDataset(trainSubjectFile, trainLabelFile, trainDataFile)
test <- loadDataset(testSubjectFile, testLabelFile, testDataFile)

if (ncol(train) != ncol(test)) {
  stop('The datasets do not have the same number of columns and can therefore not be combined')
}

if (!identical(names(train), names(test))) {
  stop('The column names or column order of the datasets do not match and can therefore not be combined')
}

```
The following shows a sample of what the datasets look like. Note that only some of the colums were included.
```{r step8b}
head(train[c(1:6, 562,563)])

```

We can also see that the training set has 7352 observations and 563 variables where the test set has 2947 and 563 respectively.
```{r step8c}
dim(train)
dim(test)
```

Step 9: Combine the two datasets and remove columns not containing mean or std
--------------------------------

```{r step9}
fullDataset <- rbind(train, test)
ds <- getColumnsContaining(fullDataset, c("mean", "Mean", "std", "Std", "subjectId", "activityLabelId"))
```

Step 10: Add the activityName factor and remove the activityLabelId
--------------------------------

```{r step10}
ds$activityName <- activities$activityName[match(ds$activityLabelId, activities$activityId)]
ds <- ds[,!(names(ds) %in% "activityLabelId")]
```

The following shows a sample of what the dataset look like. Note that only some of the colums were included.
```{r step10b}
head(ds[c(1:6, 87,88)])

```

We can also see that the training set has 10299 observations and 88 variables. The number of observations relates to the value indicated in the original study.
```{r step10c}
dim(ds)
```

The following provides a list of column names that are left in the dataset.
```{r step10d}
names(ds)
```


Step 11: Write the first dataset
--------------------------------

```{r step11}
write.csv(ds, paste(path, "full_dataset.txt", sep="/"), row.names = FALSE, quote=FALSE)
```

Step 12: Summarise the dataset
--------------------------------
The summary dataset includes the mean of all the variables (columns) broken down by subjectId and activityName.

```{r step12}
result <- aggregate(. ~ subjectId + activityName, data=ds, FUN=mean)
```

The following shows a sample of what the summary dataset look like. Note that only some of the colums were included.
```{r step12b}
head(result[c(1:6, 87,88)])

```

We can also see that the training set has 180 observations and 88 variables.
```{r step12c}
dim(result)
```

Step 13: Write the second dataset
--------------------------------

```{r step13}
write.csv(result, paste(path, "avg_by_subject_dataset.txt", sep="/"), row.names = FALSE, quote=FALSE)
```

