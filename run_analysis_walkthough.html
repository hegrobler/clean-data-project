<!DOCTYPE html>
<!-- saved from url=(0014)about:internet -->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<meta http-equiv="x-ua-compatible" content="IE=9" >

<title>Coursera Cleaning Data Project</title>

<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 12px;
   margin: 8px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 { 
   font-size:2.2em; 
}

h2 { 
   font-size:1.8em; 
}

h3 { 
   font-size:1.4em; 
}

h4 { 
   font-size:1.0em; 
}

h5 { 
   font-size:0.9em; 
}

h6 { 
   font-size:0.8em; 
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre {	
   margin-top: 0;
   max-width: 95%;
   border: 1px solid #ccc;
   white-space: pre-wrap;
}

pre code {
   display: block; padding: 0.5em;
}

code.r, code.cpp {
   background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * { 
      background: transparent !important; 
      color: black !important; 
      filter:none !important; 
      -ms-filter: none !important; 
   }

   body { 
      font-size:12pt; 
      max-width:100%; 
   }
       
   a, a:visited { 
      text-decoration: underline; 
   }

   hr { 
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote { 
      padding-right: 1em; 
      page-break-inside: avoid; 
   }

   tr, img { 
      page-break-inside: avoid; 
   }

   img { 
      max-width: 100% !important; 
   }

   @page :left { 
      margin: 15mm 20mm 15mm 10mm; 
   }
     
   @page :right { 
      margin: 15mm 10mm 15mm 20mm; 
   }

   p, h2, h3 { 
      orphans: 3; widows: 3; 
   }

   h2, h3 { 
      page-break-after: avoid; 
   }
}

</style>

<!-- Styles for R syntax highlighter -->
<style type="text/css">
   pre .operator,
   pre .paren {
     color: rgb(104, 118, 135)
   }

   pre .literal {
     color: rgb(88, 72, 246)
   }

   pre .number {
     color: rgb(0, 0, 205);
   }

   pre .comment {
     color: rgb(76, 136, 107);
   }

   pre .keyword {
     color: rgb(0, 0, 255);
   }

   pre .identifier {
     color: rgb(0, 0, 0);
   }

   pre .string {
     color: rgb(3, 106, 7);
   }
</style>

<!-- R syntax highlighter -->
<script type="text/javascript">
var hljs=new function(){function m(p){return p.replace(/&/gm,"&amp;").replace(/</gm,"&lt;")}function f(r,q,p){return RegExp(q,"m"+(r.cI?"i":"")+(p?"g":""))}function b(r){for(var p=0;p<r.childNodes.length;p++){var q=r.childNodes[p];if(q.nodeName=="CODE"){return q}if(!(q.nodeType==3&&q.nodeValue.match(/\s+/))){break}}}function h(t,s){var p="";for(var r=0;r<t.childNodes.length;r++){if(t.childNodes[r].nodeType==3){var q=t.childNodes[r].nodeValue;if(s){q=q.replace(/\n/g,"")}p+=q}else{if(t.childNodes[r].nodeName=="BR"){p+="\n"}else{p+=h(t.childNodes[r])}}}if(/MSIE [678]/.test(navigator.userAgent)){p=p.replace(/\r/g,"\n")}return p}function a(s){var r=s.className.split(/\s+/);r=r.concat(s.parentNode.className.split(/\s+/));for(var q=0;q<r.length;q++){var p=r[q].replace(/^language-/,"");if(e[p]){return p}}}function c(q){var p=[];(function(s,t){for(var r=0;r<s.childNodes.length;r++){if(s.childNodes[r].nodeType==3){t+=s.childNodes[r].nodeValue.length}else{if(s.childNodes[r].nodeName=="BR"){t+=1}else{if(s.childNodes[r].nodeType==1){p.push({event:"start",offset:t,node:s.childNodes[r]});t=arguments.callee(s.childNodes[r],t);p.push({event:"stop",offset:t,node:s.childNodes[r]})}}}}return t})(q,0);return p}function k(y,w,x){var q=0;var z="";var s=[];function u(){if(y.length&&w.length){if(y[0].offset!=w[0].offset){return(y[0].offset<w[0].offset)?y:w}else{return w[0].event=="start"?y:w}}else{return y.length?y:w}}function t(D){var A="<"+D.nodeName.toLowerCase();for(var B=0;B<D.attributes.length;B++){var C=D.attributes[B];A+=" "+C.nodeName.toLowerCase();if(C.value!==undefined&&C.value!==false&&C.value!==null){A+='="'+m(C.value)+'"'}}return A+">"}while(y.length||w.length){var v=u().splice(0,1)[0];z+=m(x.substr(q,v.offset-q));q=v.offset;if(v.event=="start"){z+=t(v.node);s.push(v.node)}else{if(v.event=="stop"){var p,r=s.length;do{r--;p=s[r];z+=("</"+p.nodeName.toLowerCase()+">")}while(p!=v.node);s.splice(r,1);while(r<s.length){z+=t(s[r]);r++}}}}return z+m(x.substr(q))}function j(){function q(x,y,v){if(x.compiled){return}var u;var s=[];if(x.k){x.lR=f(y,x.l||hljs.IR,true);for(var w in x.k){if(!x.k.hasOwnProperty(w)){continue}if(x.k[w] instanceof Object){u=x.k[w]}else{u=x.k;w="keyword"}for(var r in u){if(!u.hasOwnProperty(r)){continue}x.k[r]=[w,u[r]];s.push(r)}}}if(!v){if(x.bWK){x.b="\\b("+s.join("|")+")\\s"}x.bR=f(y,x.b?x.b:"\\B|\\b");if(!x.e&&!x.eW){x.e="\\B|\\b"}if(x.e){x.eR=f(y,x.e)}}if(x.i){x.iR=f(y,x.i)}if(x.r===undefined){x.r=1}if(!x.c){x.c=[]}x.compiled=true;for(var t=0;t<x.c.length;t++){if(x.c[t]=="self"){x.c[t]=x}q(x.c[t],y,false)}if(x.starts){q(x.starts,y,false)}}for(var p in e){if(!e.hasOwnProperty(p)){continue}q(e[p].dM,e[p],true)}}function d(B,C){if(!j.called){j();j.called=true}function q(r,M){for(var L=0;L<M.c.length;L++){if((M.c[L].bR.exec(r)||[null])[0]==r){return M.c[L]}}}function v(L,r){if(D[L].e&&D[L].eR.test(r)){return 1}if(D[L].eW){var M=v(L-1,r);return M?M+1:0}return 0}function w(r,L){return L.i&&L.iR.test(r)}function K(N,O){var M=[];for(var L=0;L<N.c.length;L++){M.push(N.c[L].b)}var r=D.length-1;do{if(D[r].e){M.push(D[r].e)}r--}while(D[r+1].eW);if(N.i){M.push(N.i)}return f(O,M.join("|"),true)}function p(M,L){var N=D[D.length-1];if(!N.t){N.t=K(N,E)}N.t.lastIndex=L;var r=N.t.exec(M);return r?[M.substr(L,r.index-L),r[0],false]:[M.substr(L),"",true]}function z(N,r){var L=E.cI?r[0].toLowerCase():r[0];var M=N.k[L];if(M&&M instanceof Array){return M}return false}function F(L,P){L=m(L);if(!P.k){return L}var r="";var O=0;P.lR.lastIndex=0;var M=P.lR.exec(L);while(M){r+=L.substr(O,M.index-O);var N=z(P,M);if(N){x+=N[1];r+='<span class="'+N[0]+'">'+M[0]+"</span>"}else{r+=M[0]}O=P.lR.lastIndex;M=P.lR.exec(L)}return r+L.substr(O,L.length-O)}function J(L,M){if(M.sL&&e[M.sL]){var r=d(M.sL,L);x+=r.keyword_count;return r.value}else{return F(L,M)}}function I(M,r){var L=M.cN?'<span class="'+M.cN+'">':"";if(M.rB){y+=L;M.buffer=""}else{if(M.eB){y+=m(r)+L;M.buffer=""}else{y+=L;M.buffer=r}}D.push(M);A+=M.r}function G(N,M,Q){var R=D[D.length-1];if(Q){y+=J(R.buffer+N,R);return false}var P=q(M,R);if(P){y+=J(R.buffer+N,R);I(P,M);return P.rB}var L=v(D.length-1,M);if(L){var O=R.cN?"</span>":"";if(R.rE){y+=J(R.buffer+N,R)+O}else{if(R.eE){y+=J(R.buffer+N,R)+O+m(M)}else{y+=J(R.buffer+N+M,R)+O}}while(L>1){O=D[D.length-2].cN?"</span>":"";y+=O;L--;D.length--}var r=D[D.length-1];D.length--;D[D.length-1].buffer="";if(r.starts){I(r.starts,"")}return R.rE}if(w(M,R)){throw"Illegal"}}var E=e[B];var D=[E.dM];var A=0;var x=0;var y="";try{var s,u=0;E.dM.buffer="";do{s=p(C,u);var t=G(s[0],s[1],s[2]);u+=s[0].length;if(!t){u+=s[1].length}}while(!s[2]);if(D.length>1){throw"Illegal"}return{r:A,keyword_count:x,value:y}}catch(H){if(H=="Illegal"){return{r:0,keyword_count:0,value:m(C)}}else{throw H}}}function g(t){var p={keyword_count:0,r:0,value:m(t)};var r=p;for(var q in e){if(!e.hasOwnProperty(q)){continue}var s=d(q,t);s.language=q;if(s.keyword_count+s.r>r.keyword_count+r.r){r=s}if(s.keyword_count+s.r>p.keyword_count+p.r){r=p;p=s}}if(r.language){p.second_best=r}return p}function i(r,q,p){if(q){r=r.replace(/^((<[^>]+>|\t)+)/gm,function(t,w,v,u){return w.replace(/\t/g,q)})}if(p){r=r.replace(/\n/g,"<br>")}return r}function n(t,w,r){var x=h(t,r);var v=a(t);var y,s;if(v){y=d(v,x)}else{return}var q=c(t);if(q.length){s=document.createElement("pre");s.innerHTML=y.value;y.value=k(q,c(s),x)}y.value=i(y.value,w,r);var u=t.className;if(!u.match("(\\s|^)(language-)?"+v+"(\\s|$)")){u=u?(u+" "+v):v}if(/MSIE [678]/.test(navigator.userAgent)&&t.tagName=="CODE"&&t.parentNode.tagName=="PRE"){s=t.parentNode;var p=document.createElement("div");p.innerHTML="<pre><code>"+y.value+"</code></pre>";t=p.firstChild.firstChild;p.firstChild.cN=s.cN;s.parentNode.replaceChild(p.firstChild,s)}else{t.innerHTML=y.value}t.className=u;t.result={language:v,kw:y.keyword_count,re:y.r};if(y.second_best){t.second_best={language:y.second_best.language,kw:y.second_best.keyword_count,re:y.second_best.r}}}function o(){if(o.called){return}o.called=true;var r=document.getElementsByTagName("pre");for(var p=0;p<r.length;p++){var q=b(r[p]);if(q){n(q,hljs.tabReplace)}}}function l(){if(window.addEventListener){window.addEventListener("DOMContentLoaded",o,false);window.addEventListener("load",o,false)}else{if(window.attachEvent){window.attachEvent("onload",o)}else{window.onload=o}}}var e={};this.LANGUAGES=e;this.highlight=d;this.highlightAuto=g;this.fixMarkup=i;this.highlightBlock=n;this.initHighlighting=o;this.initHighlightingOnLoad=l;this.IR="[a-zA-Z][a-zA-Z0-9_]*";this.UIR="[a-zA-Z_][a-zA-Z0-9_]*";this.NR="\\b\\d+(\\.\\d+)?";this.CNR="\\b(0[xX][a-fA-F0-9]+|(\\d+(\\.\\d*)?|\\.\\d+)([eE][-+]?\\d+)?)";this.BNR="\\b(0b[01]+)";this.RSR="!|!=|!==|%|%=|&|&&|&=|\\*|\\*=|\\+|\\+=|,|\\.|-|-=|/|/=|:|;|<|<<|<<=|<=|=|==|===|>|>=|>>|>>=|>>>|>>>=|\\?|\\[|\\{|\\(|\\^|\\^=|\\||\\|=|\\|\\||~";this.ER="(?![\\s\\S])";this.BE={b:"\\\\.",r:0};this.ASM={cN:"string",b:"'",e:"'",i:"\\n",c:[this.BE],r:0};this.QSM={cN:"string",b:'"',e:'"',i:"\\n",c:[this.BE],r:0};this.CLCM={cN:"comment",b:"//",e:"$"};this.CBLCLM={cN:"comment",b:"/\\*",e:"\\*/"};this.HCM={cN:"comment",b:"#",e:"$"};this.NM={cN:"number",b:this.NR,r:0};this.CNM={cN:"number",b:this.CNR,r:0};this.BNM={cN:"number",b:this.BNR,r:0};this.inherit=function(r,s){var p={};for(var q in r){p[q]=r[q]}if(s){for(var q in s){p[q]=s[q]}}return p}}();hljs.LANGUAGES.cpp=function(){var a={keyword:{"false":1,"int":1,"float":1,"while":1,"private":1,"char":1,"catch":1,"export":1,virtual:1,operator:2,sizeof:2,dynamic_cast:2,typedef:2,const_cast:2,"const":1,struct:1,"for":1,static_cast:2,union:1,namespace:1,unsigned:1,"long":1,"throw":1,"volatile":2,"static":1,"protected":1,bool:1,template:1,mutable:1,"if":1,"public":1,friend:2,"do":1,"return":1,"goto":1,auto:1,"void":2,"enum":1,"else":1,"break":1,"new":1,extern:1,using:1,"true":1,"class":1,asm:1,"case":1,typeid:1,"short":1,reinterpret_cast:2,"default":1,"double":1,register:1,explicit:1,signed:1,typename:1,"try":1,"this":1,"switch":1,"continue":1,wchar_t:1,inline:1,"delete":1,alignof:1,char16_t:1,char32_t:1,constexpr:1,decltype:1,noexcept:1,nullptr:1,static_assert:1,thread_local:1,restrict:1,_Bool:1,complex:1},built_in:{std:1,string:1,cin:1,cout:1,cerr:1,clog:1,stringstream:1,istringstream:1,ostringstream:1,auto_ptr:1,deque:1,list:1,queue:1,stack:1,vector:1,map:1,set:1,bitset:1,multiset:1,multimap:1,unordered_set:1,unordered_map:1,unordered_multiset:1,unordered_multimap:1,array:1,shared_ptr:1}};return{dM:{k:a,i:"</",c:[hljs.CLCM,hljs.CBLCLM,hljs.QSM,{cN:"string",b:"'\\\\?.",e:"'",i:"."},{cN:"number",b:"\\b(\\d+(\\.\\d*)?|\\.\\d+)(u|U|l|L|ul|UL|f|F)"},hljs.CNM,{cN:"preprocessor",b:"#",e:"$"},{cN:"stl_container",b:"\\b(deque|list|queue|stack|vector|map|set|bitset|multiset|multimap|unordered_map|unordered_set|unordered_multiset|unordered_multimap|array)\\s*<",e:">",k:a,r:10,c:["self"]}]}}}();hljs.LANGUAGES.r={dM:{c:[hljs.HCM,{cN:"number",b:"\\b0[xX][0-9a-fA-F]+[Li]?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+(?:[eE][+\\-]?\\d*)?L\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+\\.(?!\\d)(?:i\\b)?",e:hljs.IMMEDIATE_RE,r:1},{cN:"number",b:"\\b\\d+(?:\\.\\d*)?(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\.\\d+(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"keyword",b:"(?:tryCatch|library|setGeneric|setGroupGeneric)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\.",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\d+(?![\\w.])",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\b(?:function)",e:hljs.IMMEDIATE_RE,r:2},{cN:"keyword",b:"(?:if|in|break|next|repeat|else|for|return|switch|while|try|stop|warning|require|attach|detach|source|setMethod|setClass)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"literal",b:"(?:NA|NA_integer_|NA_real_|NA_character_|NA_complex_)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"literal",b:"(?:NULL|TRUE|FALSE|T|F|Inf|NaN)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"identifier",b:"[a-zA-Z.][a-zA-Z0-9._]*\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"<\\-(?!\\s*\\d)",e:hljs.IMMEDIATE_RE,r:2},{cN:"operator",b:"\\->|<\\-",e:hljs.IMMEDIATE_RE,r:1},{cN:"operator",b:"%%|~",e:hljs.IMMEDIATE_RE},{cN:"operator",b:">=|<=|==|!=|\\|\\||&&|=|\\+|\\-|\\*|/|\\^|>|<|!|&|\\||\\$|:",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"%",e:"%",i:"\\n",r:1},{cN:"identifier",b:"`",e:"`",r:0},{cN:"string",b:'"',e:'"',c:[hljs.BE],r:0},{cN:"string",b:"'",e:"'",c:[hljs.BE],r:0},{cN:"paren",b:"[[({\\])}]",e:hljs.IMMEDIATE_RE,r:0}]}};
hljs.initHighlightingOnLoad();
</script>




</head>

<body>
<h1>Coursera Cleaning Data Project</h1>

<p>This file documents the <strong>run_analysis.R</strong> script. It describes each of the steps completed in the <strong>run_analysis.R</strong> script in detail.</p>

<p>The following summarizes the environment that the tests were run in. If you run into any issues please ensure that all the packages listed below are loaded:</p>

<pre><code class="r">sessionInfo()
</code></pre>

<pre><code>## R version 3.1.0 (2014-04-10)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## 
## locale:
## [1] LC_COLLATE=English_United States.1252 
## [2] LC_CTYPE=English_United States.1252   
## [3] LC_MONETARY=English_United States.1252
## [4] LC_NUMERIC=C                          
## [5] LC_TIME=English_United States.1252    
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
## [1] knitr_1.6
## 
## loaded via a namespace (and not attached):
## [1] evaluate_0.5.5 formatR_0.10   stringr_0.6.2  tools_3.1.0
</code></pre>

<pre><code class="r">Sys.time()
</code></pre>

<pre><code>## [1] &quot;2014-06-22 19:58:06 SAST&quot;
</code></pre>

<h2>Step 1: Configure directory and file paths </h2>

<p>The first line indicates the directory where <strong>run_analysis.R</strong> is located.</p>

<p><strong>Please adjust this value to suit the environment that it is run on</strong></p>

<pre><code class="r">path = getwd()
if (grep(&quot;clean-data-project&quot;, getwd()) == FALSE) {
  path &lt;- paste(getwd(), &quot;clean-data-project&quot;, sep=&quot;/&quot;)  
}

message(paste(&quot;Path:&quot;,path))
</code></pre>

<pre><code>## Path: C:/Users/Lambert/Documents/R/week3/clean-data-project
</code></pre>

<pre><code class="r">if (!file.exists(path)) {
  stop(&quot;Could not find the specified folder. Please upadte the path above&quot;)
}

#Master data
labelsFile &lt;- paste(path,&quot;/UCI HAR Dataset/activity_labels.txt&quot;, sep=&quot;&quot;)
featuresFile &lt;- paste(path,&quot;/UCI HAR Dataset/features.txt&quot;, sep=&quot;&quot;)

#Test / Training data
trainDataFile &lt;- paste(path,&quot;/UCI HAR Dataset/train/X_train.txt&quot;, sep=&quot;&quot;)
trainSubjectFile &lt;- paste(path, &quot;/UCI HAR Dataset/train/subject_train.txt&quot;, sep=&quot;&quot;)
trainLabelFile &lt;- paste(path, &quot;/UCI HAR Dataset/train/y_train.txt&quot;, sep=&quot;&quot;) 

testDataFile &lt;- paste(path,&quot;/UCI HAR Dataset/test/X_test.txt&quot;, sep=&quot;&quot;)
testSubjectFile &lt;- paste(path, &quot;/UCI HAR Dataset/test/subject_test.txt&quot;, sep=&quot;&quot;)
testLabelFile &lt;- paste(path, &quot;/UCI HAR Dataset/test/y_test.txt&quot;, sep=&quot;&quot;)
</code></pre>

<h2>Step 2: Download the data into folder clean-data-project</h2>

<p>This step may take some time to complete. In order to run the script more than once you should:</p>

<ul>
<li>Manually download the (zip file)[<a href="https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip">https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip</a>]</li>
<li>Extract the contents to <strong>UCI HAR Dataset</strong> folder. 
NOTE: This folder must be in the same location as the <strong>run_analysis.R</strong> file</li>
<li>Comment out the following 4 lines by placing a # in front of each line. Note that this will not run in the Rmd file as its main purpose is to document <strong>run_analysis.R</strong>. Commenting out the lines should be done in <strong>run_analysis.R</strong> if the files are already present</li>
</ul>

<pre><code>temp &lt;- tempfile()
download.file(&quot;https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip&quot;, temp)
unzip(temp, exdir=path)
unlink(temp)
</code></pre>

<h2>Step 3: Declare checkFileExists function</h2>

<p>This function is used to determine is a specific file exists. If it does not then it will print a message and stop the script execution</p>

<p><strong>Parameters:</strong></p>

<ul>
<li><strong>file</strong>: Path to the file</li>
<li><strong>file</strong>: Description of the file. This is used to make the error message more helpful</li>
</ul>

<pre><code class="r">checkFileExists &lt;- function (file, description) {

  if (!file.exists(file)) {
    stop(paste(description, &quot;file does not exist. Path: &quot;, file))
  }
}
</code></pre>

<h2>Step 4: Declare loadDataset function</h2>

<p>This function loads data from the different files and merges the data together into one dataset. It can be re-used to load the training set as well as the test set</p>

<p><strong>Parameters:</strong></p>

<ul>
<li><strong>subjectFile</strong>: The subjects file eg. subject_test.txt</li>
<li><strong>labelFile</strong>: The activity labels file eg. y_test.txt</li>
<li><strong>dataFile</strong>: The main data file eg. X_test.txt</li>
</ul>

<p>See <strong>run_analysis.md</strong> for more information on these files and the their contents</p>

<pre><code class="r">loadDataset &lt;- function(subjectFile, labelFile, dataFile) {
  #Check that the files exist
  checkFileExists(subjectFile, &quot;Subject&quot;)
  checkFileExists(labelFile, &quot;Labels&quot;)
  checkFileExists(dataFile, &quot;Dataset&quot;)

  #Load subject data
  subject &lt;- read.csv(subjectFile, header=FALSE, sep=&quot; &quot;, col.names=c(&quot;subjectId&quot;))

  #Load activityLables data
  activityLabels &lt;- read.csv(labelFile, header=FALSE, sep=&quot; &quot;, col.names=c(&quot;activityLabelId&quot;))

  #load data
  dataset &lt;- read.csv(dataFile, header=FALSE, sep=&quot;&quot;, col.names=features$featureName)

  #Ensure that the lines from the three files correspond to ensure that there is no missing data
  if (nrow(activityLabels) != nrow(dataset) || nrow(dataset) != nrow(subject)) {
    print(&quot;The amount of rows in the dataset, subject and activity label files are not equal&quot;)
    print(paste(&quot;Dataset:&quot;, nrow(dataset),&quot;Subject:&quot;,nrow(subject), &quot;Activity Labels:&quot;, nrow(activityLabels)))
    stop()
  }

  #Add a subjectId column to the dataset based on the subject file
  dataset$subjectId &lt;- subject$subjectId

  #Add a activityLabelId column to the dataset based on the activityLables file
  dataset$activityLabelId &lt;- activityLabels$activityLabelId

  return(dataset)
}
</code></pre>

<h2>Step 5: Declare getColumnsContaining function</h2>

<p>This function is used to extract specific columns from a data frame based on a naming pattern.</p>

<p><strong>Parameters:</strong></p>

<ul>
<li><strong>x</strong>: Data frame to filter</li>
<li><strong>patterns</strong>: A character vector containing the naming patterns of columns to extract. Matching consist of a simple contains. Eg pattern &ldquo;mean&rdquo; will extract all columns that have mean anywhere in the column name. </li>
</ul>

<pre><code class="r">getColumnsContaining &lt;- function(x, patterns) {

  columnIndexes &lt;- c();

  for(i in 1:length(patterns)){
    #Extract the column indexes of the columns that must be included
    indexes &lt;- grep(patterns[i], names(x), fixed = TRUE)
    columnIndexes &lt;- c(columnIndexes, indexes)
  }

  #Sort the columns by index so that they are in the same order as before
  columnIndexes &lt;- sort(columnIndexes)

  x[columnIndexes]
}
</code></pre>

<h2>Step 6: Load activity labels</h2>

<p>The activity labels are loaded from the specified file and appropriate column names assigned</p>

<pre><code class="r">activities &lt;- read.csv(labelsFile, header=FALSE, sep=&quot; &quot;)
names(activities) &lt;- c(&quot;activityId&quot;, &quot;activityName&quot;)
</code></pre>

<p>This is some sample content from the file</p>

<pre><code>##   activityId       activityName
## 1          1            WALKING
## 2          2   WALKING_UPSTAIRS
## 3          3 WALKING_DOWNSTAIRS
## 4          4            SITTING
## 5          5           STANDING
## 6          6             LAYING
</code></pre>

<h2>Step 7: Load features and remove all non-alphanumeric characters from the names</h2>

<p>As indicated in the CodeBook.md file, there are some characters that are not allowed in column names. These characters include (), and -. R normally replace these characters automatically with full stops. Eg tBodyAcc-mean()-X becomes tBodyAcc.mean&hellip;X. These characters were removed in order to ensure consistency and compatibility with other programming languages. For example tBodyAcc-mean()-X is changed to become tBodyAccmeanX. Keeping the name consistent with the original feature name ensures that studies are comparable irrespective of the original dataset being used or the output of this exercise.</p>

<pre><code class="r">features &lt;- read.csv(featuresFile, header=FALSE, sep=&quot; &quot;)
names(features) &lt;- c(&quot;featureId&quot;, &quot;featureName&quot;)
</code></pre>

<p>This is some sample content bedore the names are cleansed</p>

<pre><code>##   featureId       featureName
## 1         1 tBodyAcc-mean()-X
## 2         2 tBodyAcc-mean()-Y
## 3         3 tBodyAcc-mean()-Z
## 4         4  tBodyAcc-std()-X
## 5         5  tBodyAcc-std()-Y
## 6         6  tBodyAcc-std()-Z
</code></pre>

<p>Remove all characters that are not numbers or letters</p>

<pre><code class="r">features$featureName &lt;- gsub(&quot;[^[:alnum:] ]&quot;, &quot;&quot;, features$featureName)
features$featureName &lt;- make.names(features$featureName, unique=TRUE)
</code></pre>

<p>This is some sample content after the names have been cleansed</p>

<pre><code>##   featureId   featureName
## 1         1 tBodyAccmeanX
## 2         2 tBodyAccmeanY
## 3         3 tBodyAccmeanZ
## 4         4  tBodyAccstdX
## 5         5  tBodyAccstdY
## 6         6  tBodyAccstdZ
</code></pre>

<h2>Step 8: Load the training and test data set and validate that the columns correspond </h2>

<pre><code class="r">train &lt;- loadDataset(trainSubjectFile, trainLabelFile, trainDataFile)
test &lt;- loadDataset(testSubjectFile, testLabelFile, testDataFile)

if (ncol(train) != ncol(test)) {
  stop(&#39;The datasets do not have the same number of columns and can therefore not be combined&#39;)
}

if (!identical(names(train), names(test))) {
  stop(&#39;The column names or column order of the datasets do not match and can therefore not be combined&#39;)
}
</code></pre>

<p>The following shows a sample of what the datasets look like. Note that only some of the colums were included.</p>

<pre><code class="r">head(train[c(1:6, 562,563)])
</code></pre>

<pre><code>##   tBodyAccmeanX tBodyAccmeanY tBodyAccmeanZ tBodyAccstdX tBodyAccstdY
## 1        0.2886      -0.02029       -0.1329      -0.9953      -0.9831
## 2        0.2784      -0.01641       -0.1235      -0.9982      -0.9753
## 3        0.2797      -0.01947       -0.1135      -0.9954      -0.9672
## 4        0.2792      -0.02620       -0.1233      -0.9961      -0.9834
## 5        0.2766      -0.01657       -0.1154      -0.9981      -0.9808
## 6        0.2772      -0.01010       -0.1051      -0.9973      -0.9905
##   tBodyAccstdZ subjectId activityLabelId
## 1      -0.9135         1               5
## 2      -0.9603         1               5
## 3      -0.9789         1               5
## 4      -0.9907         1               5
## 5      -0.9905         1               5
## 6      -0.9954         1               5
</code></pre>

<p>We can also see that the training set has 7352 observations and 563 variables where the test set has 2947 and 563 respectively.</p>

<pre><code class="r">dim(train)
</code></pre>

<pre><code>## [1] 7352  563
</code></pre>

<pre><code class="r">dim(test)
</code></pre>

<pre><code>## [1] 2947  563
</code></pre>

<h2>Step 9: Combine the two datasets and remove columns not containing mean or std</h2>

<pre><code class="r">fullDataset &lt;- rbind(train, test)
ds &lt;- getColumnsContaining(fullDataset, c(&quot;mean&quot;, &quot;Mean&quot;, &quot;std&quot;, &quot;Std&quot;, &quot;subjectId&quot;, &quot;activityLabelId&quot;))
</code></pre>

<h2>Step 10: Add the activityName factor and remove the activityLabelId</h2>

<pre><code class="r">ds$activityName &lt;- activities$activityName[match(ds$activityLabelId, activities$activityId)]
ds &lt;- ds[,!(names(ds) %in% &quot;activityLabelId&quot;)]
</code></pre>

<p>The following shows a sample of what the dataset look like. Note that only some of the colums were included.</p>

<pre><code class="r">head(ds[c(1:6, 87,88)])
</code></pre>

<pre><code>##   tBodyAccmeanX tBodyAccmeanY tBodyAccmeanZ tBodyAccstdX tBodyAccstdY
## 1        0.2886      -0.02029       -0.1329      -0.9953      -0.9831
## 2        0.2784      -0.01641       -0.1235      -0.9982      -0.9753
## 3        0.2797      -0.01947       -0.1135      -0.9954      -0.9672
## 4        0.2792      -0.02620       -0.1233      -0.9961      -0.9834
## 5        0.2766      -0.01657       -0.1154      -0.9981      -0.9808
## 6        0.2772      -0.01010       -0.1051      -0.9973      -0.9905
##   tBodyAccstdZ subjectId activityName
## 1      -0.9135         1     STANDING
## 2      -0.9603         1     STANDING
## 3      -0.9789         1     STANDING
## 4      -0.9907         1     STANDING
## 5      -0.9905         1     STANDING
## 6      -0.9954         1     STANDING
</code></pre>

<p>We can also see that the training set has 10299 observations and 88 variables. The number of observations relates to the value indicated in the original study.</p>

<pre><code class="r">dim(ds)
</code></pre>

<pre><code>## [1] 10299    88
</code></pre>

<p>The following provides a list of column names that are left in the dataset.</p>

<pre><code class="r">names(ds)
</code></pre>

<pre><code>##  [1] &quot;tBodyAccmeanX&quot;                    
##  [2] &quot;tBodyAccmeanY&quot;                    
##  [3] &quot;tBodyAccmeanZ&quot;                    
##  [4] &quot;tBodyAccstdX&quot;                     
##  [5] &quot;tBodyAccstdY&quot;                     
##  [6] &quot;tBodyAccstdZ&quot;                     
##  [7] &quot;tGravityAccmeanX&quot;                 
##  [8] &quot;tGravityAccmeanY&quot;                 
##  [9] &quot;tGravityAccmeanZ&quot;                 
## [10] &quot;tGravityAccstdX&quot;                  
## [11] &quot;tGravityAccstdY&quot;                  
## [12] &quot;tGravityAccstdZ&quot;                  
## [13] &quot;tBodyAccJerkmeanX&quot;                
## [14] &quot;tBodyAccJerkmeanY&quot;                
## [15] &quot;tBodyAccJerkmeanZ&quot;                
## [16] &quot;tBodyAccJerkstdX&quot;                 
## [17] &quot;tBodyAccJerkstdY&quot;                 
## [18] &quot;tBodyAccJerkstdZ&quot;                 
## [19] &quot;tBodyGyromeanX&quot;                   
## [20] &quot;tBodyGyromeanY&quot;                   
## [21] &quot;tBodyGyromeanZ&quot;                   
## [22] &quot;tBodyGyrostdX&quot;                    
## [23] &quot;tBodyGyrostdY&quot;                    
## [24] &quot;tBodyGyrostdZ&quot;                    
## [25] &quot;tBodyGyroJerkmeanX&quot;               
## [26] &quot;tBodyGyroJerkmeanY&quot;               
## [27] &quot;tBodyGyroJerkmeanZ&quot;               
## [28] &quot;tBodyGyroJerkstdX&quot;                
## [29] &quot;tBodyGyroJerkstdY&quot;                
## [30] &quot;tBodyGyroJerkstdZ&quot;                
## [31] &quot;tBodyAccMagmean&quot;                  
## [32] &quot;tBodyAccMagstd&quot;                   
## [33] &quot;tGravityAccMagmean&quot;               
## [34] &quot;tGravityAccMagstd&quot;                
## [35] &quot;tBodyAccJerkMagmean&quot;              
## [36] &quot;tBodyAccJerkMagstd&quot;               
## [37] &quot;tBodyGyroMagmean&quot;                 
## [38] &quot;tBodyGyroMagstd&quot;                  
## [39] &quot;tBodyGyroJerkMagmean&quot;             
## [40] &quot;tBodyGyroJerkMagstd&quot;              
## [41] &quot;fBodyAccmeanX&quot;                    
## [42] &quot;fBodyAccmeanY&quot;                    
## [43] &quot;fBodyAccmeanZ&quot;                    
## [44] &quot;fBodyAccstdX&quot;                     
## [45] &quot;fBodyAccstdY&quot;                     
## [46] &quot;fBodyAccstdZ&quot;                     
## [47] &quot;fBodyAccmeanFreqX&quot;                
## [48] &quot;fBodyAccmeanFreqY&quot;                
## [49] &quot;fBodyAccmeanFreqZ&quot;                
## [50] &quot;fBodyAccJerkmeanX&quot;                
## [51] &quot;fBodyAccJerkmeanY&quot;                
## [52] &quot;fBodyAccJerkmeanZ&quot;                
## [53] &quot;fBodyAccJerkstdX&quot;                 
## [54] &quot;fBodyAccJerkstdY&quot;                 
## [55] &quot;fBodyAccJerkstdZ&quot;                 
## [56] &quot;fBodyAccJerkmeanFreqX&quot;            
## [57] &quot;fBodyAccJerkmeanFreqY&quot;            
## [58] &quot;fBodyAccJerkmeanFreqZ&quot;            
## [59] &quot;fBodyGyromeanX&quot;                   
## [60] &quot;fBodyGyromeanY&quot;                   
## [61] &quot;fBodyGyromeanZ&quot;                   
## [62] &quot;fBodyGyrostdX&quot;                    
## [63] &quot;fBodyGyrostdY&quot;                    
## [64] &quot;fBodyGyrostdZ&quot;                    
## [65] &quot;fBodyGyromeanFreqX&quot;               
## [66] &quot;fBodyGyromeanFreqY&quot;               
## [67] &quot;fBodyGyromeanFreqZ&quot;               
## [68] &quot;fBodyAccMagmean&quot;                  
## [69] &quot;fBodyAccMagstd&quot;                   
## [70] &quot;fBodyAccMagmeanFreq&quot;              
## [71] &quot;fBodyBodyAccJerkMagmean&quot;          
## [72] &quot;fBodyBodyAccJerkMagstd&quot;           
## [73] &quot;fBodyBodyAccJerkMagmeanFreq&quot;      
## [74] &quot;fBodyBodyGyroMagmean&quot;             
## [75] &quot;fBodyBodyGyroMagstd&quot;              
## [76] &quot;fBodyBodyGyroMagmeanFreq&quot;         
## [77] &quot;fBodyBodyGyroJerkMagmean&quot;         
## [78] &quot;fBodyBodyGyroJerkMagstd&quot;          
## [79] &quot;fBodyBodyGyroJerkMagmeanFreq&quot;     
## [80] &quot;angletBodyAccMeangravity&quot;         
## [81] &quot;angletBodyAccJerkMeangravityMean&quot; 
## [82] &quot;angletBodyGyroMeangravityMean&quot;    
## [83] &quot;angletBodyGyroJerkMeangravityMean&quot;
## [84] &quot;angleXgravityMean&quot;                
## [85] &quot;angleYgravityMean&quot;                
## [86] &quot;angleZgravityMean&quot;                
## [87] &quot;subjectId&quot;                        
## [88] &quot;activityName&quot;
</code></pre>

<h2>Step 11: Write the first dataset</h2>

<pre><code class="r">write.csv(ds, paste(path, &quot;full_dataset.txt&quot;, sep=&quot;/&quot;), row.names = FALSE, quote=FALSE)
</code></pre>

<h2>Step 12: Summarise the dataset</h2>

<p>The summary dataset includes the mean of all the variables (columns) broken down by subjectId and activityName.</p>

<pre><code class="r">result &lt;- aggregate(. ~ subjectId + activityName, data=ds, FUN=mean)
</code></pre>

<p>The following shows a sample of what the summary dataset look like. Note that only some of the colums were included.</p>

<pre><code class="r">head(result[c(1:6, 87,88)])
</code></pre>

<pre><code>##   subjectId activityName tBodyAccmeanX tBodyAccmeanY tBodyAccmeanZ
## 1         1       LAYING        0.2216      -0.04051       -0.1132
## 2         2       LAYING        0.2814      -0.01816       -0.1072
## 3         3       LAYING        0.2755      -0.01896       -0.1013
## 4         4       LAYING        0.2636      -0.01500       -0.1107
## 5         5       LAYING        0.2783      -0.01830       -0.1079
## 6         6       LAYING        0.2487      -0.01025       -0.1331
##   tBodyAccstdX angleYgravityMean angleZgravityMean
## 1      -0.9281           -0.5203           -0.3524
## 2      -0.9741           -0.5197           -0.4789
## 3      -0.9828           -0.6301           -0.3462
## 4      -0.9542           -0.7632           -0.2298
## 5      -0.9659           -0.8253           -0.1681
## 6      -0.9340           -0.8746           -0.1066
</code></pre>

<p>We can also see that the training set has 180 observations and 88 variables.</p>

<pre><code class="r">dim(result)
</code></pre>

<pre><code>## [1] 180  88
</code></pre>

<h2>Step 13: Write the second dataset</h2>

<pre><code class="r">write.csv(result, paste(path, &quot;avg_by_subject_dataset.txt&quot;, sep=&quot;/&quot;), row.names = FALSE, quote=FALSE)
</code></pre>

</body>

</html>

